{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 블로그 원본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 정보 가져오기 및 headers 세팅\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n",
    "            'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'}\n",
    "# 뉴스 제목 url\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "# http 요청 받기\n",
    "response = requests.get(url,headers=headers)\n",
    "# url에 대한 정보를 받을 수 있는 soup 생성\n",
    "soup = BeautifulSoup(response.text,'lxml')\n",
    "\n",
    "news_title=[title.get('title') for title in soup.select('.title') if title.get('title') != None]\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### gpt 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# investing.com에서 BTC 뉴스 페이지 URL\n",
    "url = 'https://www.investing.com/crypto/bitcoin/news'\n",
    "\n",
    "# HTTP GET 요청을 보내서 페이지 내용 가져오기\n",
    "response = requests.get(url)\n",
    "\n",
    "# 요청이 성공했는지 확인\n",
    "if response.status_code == 200:\n",
    "    # 페이지 내용을 BeautifulSoup을 사용하여 파싱\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 뉴스 제목들을 찾기 위한 CSS 클래스 확인\n",
    "    news_titles = soup.select('.largeTitle a')\n",
    "\n",
    "    # 각 뉴스 제목 출력\n",
    "    for title in news_titles:\n",
    "        print(title.text.strip())\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')\n",
    "    \n",
    "print(news_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### gpt 수정 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# html 정보 가져오기 및 headers 세팅\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'\n",
    "}\n",
    "\n",
    "# 뉴스 제목 url\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "\n",
    "# http 요청 받기\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# url에 대한 정보를 받을 수 있는 soup 생성\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 뉴스 제목 선택\n",
    "news_titles = [title.text.strip() for title in soup.select('.font-bold.hover\\\\:underline')]\n",
    "\n",
    "# 결과 출력\n",
    "print(news_titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 자동 크롬드라이버 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 특정 버전의 ChromeDriver 사용\n",
    "chrome_driver_path = ChromeDriverManager(browser_version=\"114.0.5735.90\").install()\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "# Selenium으로 웹페이지 열기\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "\n",
    "# 현재 페이지 소스코드 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup을 사용하여 뉴스 제목 추출\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "news_titles = [title.text.strip() for title in soup.select('.font-bold.hover\\\\:underline')]\n",
    "\n",
    "# 결과 출력\n",
    "print(news_titles)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 수동 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Enforcement Directorate arrests Katalyst executive in Bitcoin scam', 'Shiba Inu (SHIB) Becoming Bullish, Ethereum (ETH) Price Screams Rally Continuation, Bitcoin (BTC) Not Giving up Market Dominance', 'Crypto social media accounts hacked, spreading misinformation', 'BTIG upgrades Marathon Digital as Bitcoin draws attention after spot ETF approvals', 'Binance Issues Important Notice for BTC, XRP, ADA Futures Traders: Details', 'VanEck to liquidate Bitcoin Strategy ETF following SEC nod', \"BlackRock to Become BTC Biggest Holder, Analyst Predicts; Michael Saylor Issues Warning for BTC Holders; SHIB Rep Unveils Shibarium's Future: Crypto News Digest by U.Today\", 'JPMorgan CEO remains skeptical about Bitcoin as price dips', \"Max Keiser Points to BTC Price Growth Estimate, Justin Sun Withdraws $13.8 Million ETH From Binance, Elon Musk's Post Sparks SHIB, XRP Armies' Curiosity: Crypto News Digest by U.Today\", 'Ethereum (ETH) Makes Comeback, Finally', 'Find a Crypto Broker']\n",
      "뉴스 헤더가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정\n",
    "chrome_driver_path = 'C:\\education\\ml_dev\\coin\\jh_-\\investing\\chromedriver-win64'  # 자신의 크롬 드라이버 경로로 변경\n",
    "\n",
    "# Selenium으로 웹페이지 열기\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(url)\n",
    "time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "\n",
    "# 현재 페이지 소스코드 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup을 사용하여 뉴스 제목 추출\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "news_titles = [title.text.strip() for title in soup.select('.font-bold.hover\\\\:underline')]\n",
    "\n",
    "# 결과 출력\n",
    "print(news_titles)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 뉴스 헤더를 JSON 파일로 저장\n",
    "result_data = {'news_titles': news_titles}\n",
    "with open('bitcoin_news_titles.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 헤더가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 전체 페이지에 대한 뉴스 제목과 본문을 json로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 헤더가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정 (자신의 크롬 드라이버 경로로 변경)\n",
    "chrome_driver_path = 'C:\\\\education\\\\ml_dev\\\\coin\\\\jh_-\\\\investing\\\\chromedriver-win64'\n",
    "\n",
    "# Selenium으로 웹페이지 열기 함수\n",
    "def get_news_titles(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "    \n",
    "    # 현재 페이지 소스코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 뉴스 제목 추출\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    news_titles = [title.text.strip() for title in soup.select('.textDiv')]\n",
    "    \n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "    \n",
    "    return news_titles\n",
    "\n",
    "# 여러 페이지의 뉴스 헤더를 저장할 리스트\n",
    "all_news_titles = []\n",
    "\n",
    "# 1부터 100까지의 페이지에 대해 뉴스 헤더를 가져와서 리스트에 추가\n",
    "for page_number in range(1, 2):\n",
    "    url = f\"https://www.investing.com/news/cryptocurrency-news/{page_number}\"\n",
    "    news_titles = get_news_titles(url)\n",
    "    all_news_titles.extend(news_titles)\n",
    "\n",
    "# 뉴스 헤더를 JSON 파일로 저장\n",
    "result_data = {'news_titles': all_news_titles}\n",
    "with open('2all_bitcoin_news_titles.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 헤더가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 뉴스 헤더와 시간 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 정보가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정 (자신의 크롬 드라이버 경로로 변경)\n",
    "chrome_driver_path = 'C:\\\\education\\\\ml_dev\\\\coin\\\\jh_-\\\\investing\\\\chromedriver-win64'\n",
    "\n",
    "# Selenium으로 웹페이지 열기 함수\n",
    "def get_news_info(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "    \n",
    "    # 현재 페이지 소스코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 뉴스 제목과 올라온 시간 추출\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')    \n",
    "    \n",
    "    news_info_list = []\n",
    "    \n",
    "    # 뉴스 제목과 올라온 시간이 포함된 요소 선택\n",
    "    news_elements = soup.select('.largeTitle') \n",
    "    \n",
    "    for element in news_elements:\n",
    "        # largeTitle 클래스 내에서 모든 .title과 .date를 찾음\n",
    "        titles = element.select('.title')\n",
    "        dates = element.select('.date')\n",
    "        \n",
    "        # 뉴스 제목과 올라온 시간이 있는 경우에만 결과 리스트에 추가\n",
    "        for title, date in zip(titles, dates):\n",
    "            title_text = title.text.strip()\n",
    "            date_text = date.text.strip()\n",
    "            news_info_list.append({'title': title_text, 'time': date_text})\n",
    "    \n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "    \n",
    "    return news_info_list\n",
    "\n",
    "# 여러 페이지의 뉴스 정보를 저장할 리스트\n",
    "all_news_info = []\n",
    "\n",
    "# 1부터 2까지의 페이지에 대해 뉴스 정보를 가져와서 리스트에 추가\n",
    "for page_number in range(1, 3):\n",
    "    url = f\"https://www.investing.com/news/cryptocurrency-news/{page_number}\"\n",
    "    news_info = get_news_info(url)\n",
    "    all_news_info.extend(news_info)\n",
    "\n",
    "# 뉴스 정보를 JSON 파일로 저장\n",
    "result_data = {'news_info': all_news_info}\n",
    "with open('all_cryptocurrency_news_info.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 정보가 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 뉴스 본문 접속 후 헤더와 업로드시간 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument\n  (Session info: chrome-headless-shell=120.0.6099.225)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6F6152142+3514994]\n\t(No symbol) [0x00007FF6F5D70CE2]\n\t(No symbol) [0x00007FF6F5C174C3]\n\t(No symbol) [0x00007FF6F5C00F3B]\n\t(No symbol) [0x00007FF6F5BFEE85]\n\t(No symbol) [0x00007FF6F5BFF603]\n\t(No symbol) [0x00007FF6F5C1A0FD]\n\t(No symbol) [0x00007FF6F5CA2E01]\n\t(No symbol) [0x00007FF6F5C85FEA]\n\t(No symbol) [0x00007FF6F5CA28F6]\n\t(No symbol) [0x00007FF6F5C85D93]\n\t(No symbol) [0x00007FF6F5C54BDC]\n\t(No symbol) [0x00007FF6F5C55C64]\n\tGetHandleVerifier [0x00007FF6F617E16B+3695259]\n\tGetHandleVerifier [0x00007FF6F61D6737+4057191]\n\tGetHandleVerifier [0x00007FF6F61CE4E3+4023827]\n\tGetHandleVerifier [0x00007FF6F5EA04F9+689705]\n\t(No symbol) [0x00007FF6F5D7C048]\n\t(No symbol) [0x00007FF6F5D78044]\n\t(No symbol) [0x00007FF6F5D781C9]\n\t(No symbol) [0x00007FF6F5D688C4]\n\tBaseThreadInitThunk [0x00007FFCADC8257D+29]\n\tRtlUserThreadStart [0x00007FFCAF06AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     57\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.investing.com/news/cryptocurrency-news/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 58\u001b[0m     news_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_news_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     all_news_info\u001b[38;5;241m.\u001b[39mextend(news_info)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# 뉴스 정보를 JSON 파일로 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m, in \u001b[0;36mget_news_info\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m news_url \u001b[38;5;129;01min\u001b[39;00m news_urls:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m         news_page_source \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n\u001b[0;32m     35\u001b[0m         news_soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(news_page_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:357\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\ml-dev\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument\n  (Session info: chrome-headless-shell=120.0.6099.225)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6F6152142+3514994]\n\t(No symbol) [0x00007FF6F5D70CE2]\n\t(No symbol) [0x00007FF6F5C174C3]\n\t(No symbol) [0x00007FF6F5C00F3B]\n\t(No symbol) [0x00007FF6F5BFEE85]\n\t(No symbol) [0x00007FF6F5BFF603]\n\t(No symbol) [0x00007FF6F5C1A0FD]\n\t(No symbol) [0x00007FF6F5CA2E01]\n\t(No symbol) [0x00007FF6F5C85FEA]\n\t(No symbol) [0x00007FF6F5CA28F6]\n\t(No symbol) [0x00007FF6F5C85D93]\n\t(No symbol) [0x00007FF6F5C54BDC]\n\t(No symbol) [0x00007FF6F5C55C64]\n\tGetHandleVerifier [0x00007FF6F617E16B+3695259]\n\tGetHandleVerifier [0x00007FF6F61D6737+4057191]\n\tGetHandleVerifier [0x00007FF6F61CE4E3+4023827]\n\tGetHandleVerifier [0x00007FF6F5EA04F9+689705]\n\t(No symbol) [0x00007FF6F5D7C048]\n\t(No symbol) [0x00007FF6F5D78044]\n\t(No symbol) [0x00007FF6F5D781C9]\n\t(No symbol) [0x00007FF6F5D688C4]\n\tBaseThreadInitThunk [0x00007FFCADC8257D+29]\n\tRtlUserThreadStart [0x00007FFCAF06AA58+40]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정 (자신의 크롬 드라이버 경로로 변경)\n",
    "chrome_driver_path = 'C:\\\\education\\\\ml_dev\\\\coin\\\\jh_-\\\\investing\\\\chromedriver-win64'\n",
    "\n",
    "# Selenium으로 웹페이지 열기 함수\n",
    "def get_news_info(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "    \n",
    "    # 현재 페이지 소스코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 뉴스 본문 URL 추출\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    news_urls = [title.find('a')['href'] for title in soup.select('.textDiv')]\n",
    "    \n",
    "    news_info_list = []\n",
    "    \n",
    "    # 각 뉴스 페이지로 이동하여 뉴스 헤더와 업로드 시간 가져오기\n",
    "    for news_url in news_urls:\n",
    "        try:\n",
    "            driver.get(news_url)\n",
    "            news_page_source = driver.page_source\n",
    "            news_soup = BeautifulSoup(news_page_source, 'html.parser')\n",
    "            \n",
    "            # 뉴스 헤더와 업로드 시간 추출\n",
    "            news_title = news_soup.select_one('.articleHeader > h1').text.strip()\n",
    "            news_date = news_soup.select_one('.articleInfo > span.date').text.strip()\n",
    "            \n",
    "            # 결과 리스트에 추가\n",
    "            news_info_list.append({'title': news_title, 'time': news_date})\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            print(f\"뉴스 페이지에서 정보를 찾을 수 없습니다: {news_url}\")\n",
    "    \n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "    \n",
    "    return news_info_list\n",
    "\n",
    "# 여러 페이지의 뉴스 정보를 저장할 리스트\n",
    "all_news_info = []\n",
    "\n",
    "# 1부터 2까지의 페이지에 대해 뉴스 정보를 가져와서 리스트에 추가\n",
    "for page_number in range(1, 3):\n",
    "    url = f\"https://www.investing.com/news/cryptocurrency-news/{page_number}\"\n",
    "    news_info = get_news_info(url)\n",
    "    all_news_info.extend(news_info)\n",
    "\n",
    "# 뉴스 정보를 JSON 파일로 저장\n",
    "result_data = {'news_info': all_news_info}\n",
    "with open('all_cryptocurrency_news_info.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 정보가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Long Polling\n",
    "    - 서버 커넥션이 끊기자마자 바로 재요청해서 서버 커넥션 오픈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 관련 데이터는 vuex store에서 관리\n",
    "async subscribeStocks() {\n",
    "    await this.getStocks(); # 주식을 가져오는 action dispatch\n",
    "    \n",
    "    # getStocks action 내의 trycatch 문으로 에러를 잡아 stocksIsError 토클링\n",
    "    if (this.stocksIsError) {\n",
    "        this.setStocksIsError(false); # 일단 에러 무시\n",
    "        await new Promise((resolve) => setTimeout(resolve, 1000)); # 1초만 대기\n",
    "    }\n",
    "    \n",
    "    this.subscribeStocks() # 커넥션 끊기자마자 재귀호출하여 커넥션 유지\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 실시간으로 해당 뉴스 페이지에서 뉴스가 업로드되면 헤더와 업로드시간을 찍어주는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n",
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-25_cryptocurrency_news_info.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def get_news_info(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')    \n",
    "    \n",
    "    news_info_list = []\n",
    "    \n",
    "    # 뉴스 제목과 올라온 시간이 포함된 요소 선택\n",
    "    news_elements = soup.select('.largeTitle') \n",
    "    \n",
    "    for element in news_elements:\n",
    "        # largeTitle 클래스 내에서 모든 .title과 .date를 찾음\n",
    "        titles = element.select('.title')\n",
    "        dates = element.select('.date')\n",
    "        \n",
    "        # 뉴스 제목과 올라온 시간이 있는 경우에만 결과 리스트에 추가\n",
    "        for title, date in zip(titles, dates):\n",
    "            title_text = title.text.strip()\n",
    "            date_text = date.text.strip()\n",
    "            news_info_list.append({'title': title_text, 'time': date_text})\n",
    "    \n",
    "    return news_info_list\n",
    "\n",
    "def save_news_to_json(news_info_list):\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    file_name = f'{current_date}_cryptocurrency_news_info.json'\n",
    "    \n",
    "    result_data = {'news_info': news_info_list}\n",
    "    with open(file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"뉴스 정보가 성공적으로 저장되었습니다. 파일명: {file_name}\")\n",
    "\n",
    "# Long Polling을 사용하여 실시간으로 뉴스 데이터 가져오기\n",
    "while True:\n",
    "    # 현재 날짜를 기준으로 뉴스를 가져올 URL 생성\n",
    "    url = f\"https://www.investing.com/news/cryptocurrency-news/{page_number}\"\n",
    "    \n",
    "    # 뉴스 정보 가져오기\n",
    "    news_info = get_news_info(url)\n",
    "    \n",
    "    # 뉴스 정보를 JSON 파일로 저장\n",
    "    save_news_to_json(news_info)\n",
    "    \n",
    "    # 5 : 300 입력해야함 분마다 Long Polling 요청 (원하는 주기로 변경 가능)\n",
    "    time.sleep(60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
