{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 블로그 원본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 정보 가져오기 및 headers 세팅\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n",
    "            'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'}\n",
    "# 뉴스 제목 url\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "# http 요청 받기\n",
    "response = requests.get(url,headers=headers)\n",
    "# url에 대한 정보를 받을 수 있는 soup 생성\n",
    "soup = BeautifulSoup(response.text,'lxml')\n",
    "\n",
    "news_title=[title.get('title') for title in soup.select('.title') if title.get('title') != None]\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### gpt 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# investing.com에서 BTC 뉴스 페이지 URL\n",
    "url = 'https://www.investing.com/crypto/bitcoin/news'\n",
    "\n",
    "# HTTP GET 요청을 보내서 페이지 내용 가져오기\n",
    "response = requests.get(url)\n",
    "\n",
    "# 요청이 성공했는지 확인\n",
    "if response.status_code == 200:\n",
    "    # 페이지 내용을 BeautifulSoup을 사용하여 파싱\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 뉴스 제목들을 찾기 위한 CSS 클래스 확인\n",
    "    news_titles = soup.select('.largeTitle a')\n",
    "\n",
    "    # 각 뉴스 제목 출력\n",
    "    for title in news_titles:\n",
    "        print(title.text.strip())\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')\n",
    "    \n",
    "print(news_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### gpt 수정 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# html 정보 가져오기 및 headers 세팅\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'\n",
    "}\n",
    "\n",
    "# 뉴스 제목 url\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "\n",
    "# http 요청 받기\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# url에 대한 정보를 받을 수 있는 soup 생성\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 뉴스 제목 선택\n",
    "news_titles = [title.text.strip() for title in soup.select('.font-bold.hover\\\\:underline')]\n",
    "\n",
    "# 결과 출력\n",
    "print(news_titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 자동 크롬드라이버 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 특정 버전의 ChromeDriver 사용\n",
    "chrome_driver_path = ChromeDriverManager(browser_version=\"114.0.5735.90\").install()\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "# Selenium으로 웹페이지 열기\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "\n",
    "# 현재 페이지 소스코드 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup을 사용하여 뉴스 제목 추출\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "news_titles = [title.text.strip() for title in soup.select('.font-bold.hover\\\\:underline')]\n",
    "\n",
    "# 결과 출력\n",
    "print(news_titles)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 수동 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Enforcement Directorate arrests Katalyst executive in Bitcoin scam', 'Shiba Inu (SHIB) Becoming Bullish, Ethereum (ETH) Price Screams Rally Continuation, Bitcoin (BTC) Not Giving up Market Dominance', 'Crypto social media accounts hacked, spreading misinformation', 'BTIG upgrades Marathon Digital as Bitcoin draws attention after spot ETF approvals', 'Binance Issues Important Notice for BTC, XRP, ADA Futures Traders: Details', 'VanEck to liquidate Bitcoin Strategy ETF following SEC nod', \"BlackRock to Become BTC Biggest Holder, Analyst Predicts; Michael Saylor Issues Warning for BTC Holders; SHIB Rep Unveils Shibarium's Future: Crypto News Digest by U.Today\", 'JPMorgan CEO remains skeptical about Bitcoin as price dips', \"Max Keiser Points to BTC Price Growth Estimate, Justin Sun Withdraws $13.8 Million ETH From Binance, Elon Musk's Post Sparks SHIB, XRP Armies' Curiosity: Crypto News Digest by U.Today\", 'Ethereum (ETH) Makes Comeback, Finally', 'Find a Crypto Broker']\n",
      "뉴스 헤더가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정\n",
    "chrome_driver_path = 'C:\\education\\ml_dev\\coin\\jh_-\\investing\\chromedriver-win64'  # 자신의 크롬 드라이버 경로로 변경\n",
    "\n",
    "# Selenium으로 웹페이지 열기\n",
    "url = \"https://www.investing.com/crypto/bitcoin/news\"\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(url)\n",
    "time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "\n",
    "# 현재 페이지 소스코드 가져오기\n",
    "page_source = driver.page_source\n",
    "\n",
    "# BeautifulSoup을 사용하여 뉴스 제목 추출\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "news_titles = [title.text.strip() for title in soup.select('.font-bold.hover\\\\:underline')]\n",
    "\n",
    "# 결과 출력\n",
    "print(news_titles)\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# 뉴스 헤더를 JSON 파일로 저장\n",
    "result_data = {'news_titles': news_titles}\n",
    "with open('bitcoin_news_titles.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 헤더가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 전체 페이지에 대한 뉴스 제목과 본문을 json로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 헤더가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정 (자신의 크롬 드라이버 경로로 변경)\n",
    "chrome_driver_path = 'C:\\\\education\\\\ml_dev\\\\coin\\\\jh_-\\\\investing\\\\chromedriver-win64'\n",
    "\n",
    "# Selenium으로 웹페이지 열기 함수\n",
    "def get_news_titles(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "    \n",
    "    # 현재 페이지 소스코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 뉴스 제목 추출\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    news_titles = [title.text.strip() for title in soup.select('.textDiv')]\n",
    "    \n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "    \n",
    "    return news_titles\n",
    "\n",
    "# 여러 페이지의 뉴스 헤더를 저장할 리스트\n",
    "all_news_titles = []\n",
    "\n",
    "# 1부터 100까지의 페이지에 대해 뉴스 헤더를 가져와서 리스트에 추가\n",
    "for page_number in range(1, 2):\n",
    "    url = f\"https://www.investing.com/news/cryptocurrency-news/{page_number}\"\n",
    "    news_titles = get_news_titles(url)\n",
    "    all_news_titles.extend(news_titles)\n",
    "\n",
    "# 뉴스 헤더를 JSON 파일로 저장\n",
    "result_data = {'news_titles': all_news_titles}\n",
    "with open('2all_bitcoin_news_titles.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 헤더가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 뉴스 헤더와 시간 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m     56\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.investing.com/news/cryptocurrency-news/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 57\u001b[0m     news_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_news_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     all_news_info\u001b[38;5;241m.\u001b[39mextend(news_info)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# 뉴스 정보를 JSON 파일로 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 36\u001b[0m, in \u001b[0;36mget_news_info\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     32\u001b[0m news_elements \u001b[38;5;241m=\u001b[39m news_section\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjs-article-item articleItem\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m news_elements:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# 뉴스 헤더 추출\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     title_element \u001b[38;5;241m=\u001b[39m \u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlargeTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     37\u001b[0m     title \u001b[38;5;241m=\u001b[39m title_element\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mif\u001b[39;00m title_element \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# 업로드 날짜 추출\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정 (자신의 크롬 드라이버 경로로 변경)\n",
    "chrome_driver_path = 'C:\\\\education\\\\ml_dev\\\\coin\\\\jh_-\\\\investing\\\\chromedriver-win64'\n",
    "\n",
    "# Selenium으로 웹페이지 열기 함수\n",
    "def get_news_info(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "    \n",
    "    # 현재 페이지 소스코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 뉴스 헤더와 업로드 날짜 추출\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    news_info_list = []\n",
    "    \n",
    "    # Cryptocurrency News의 클래스인 <section id=\"leftColumn\" class=\"\"> 선택\n",
    "    news_section = soup.find('section', {'id': 'leftColumn', 'class': ''})\n",
    "    \n",
    "    # 뉴스 헤더와 업로드 날짜가 포함된 요소 선택\n",
    "    news_elements = news_section.find_all('article', {'class': 'js-article-item articleItem'})\n",
    "    \n",
    "    for element in news_elements:\n",
    "        # 뉴스 헤더 추출\n",
    "        title_element = element.find('div', {'class': 'largeTitle'}).find('a', {'class': 'title'})\n",
    "        title = title_element.text.strip() if title_element else None\n",
    "        \n",
    "        # 업로드 날짜 추출\n",
    "        time_element = element.find('span', {'class': 'date'})\n",
    "        time_info = time_element.text.strip() if time_element else None\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        news_info_list.append({'title': title, 'time': time_info})\n",
    "    \n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "    \n",
    "    return news_info_list\n",
    "\n",
    "# 여러 페이지의 뉴스 정보를 저장할 리스트\n",
    "all_news_info = []\n",
    "\n",
    "# 1부터 2까지의 페이지에 대해 뉴스 정보를 가져와서 리스트에 추가\n",
    "for page_number in range(1, 2):\n",
    "    url = f\"https://www.investing.com/news/cryptocurrency-news/{page_number}\"\n",
    "    news_info = get_news_info(url)\n",
    "    all_news_info.extend(news_info)\n",
    "\n",
    "# 뉴스 정보를 JSON 파일로 저장\n",
    "result_data = {'news_info': all_news_info}\n",
    "with open('all_cryptocurrency_news_info.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"뉴스 정보가 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Long Polling\n",
    "    - 서버 커넥션이 끊기자마자 바로 재요청해서 서버 커넥션 오픈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 관련 데이터는 vuex store에서 관리\n",
    "async subscribeStocks() {\n",
    "    await this.getStocks(); # 주식을 가져오는 action dispatch\n",
    "    \n",
    "    # getStocks action 내의 trycatch 문으로 에러를 잡아 stocksIsError 토클링\n",
    "    if (this.stocksIsError) {\n",
    "        this.setStocksIsError(false); # 일단 에러 무시\n",
    "        await new Promise((resolve) => setTimeout(resolve, 1000)); # 1초만 대기\n",
    "    }\n",
    "    \n",
    "    this.subscribeStocks() # 커넥션 끊기자마자 재귀호출하여 커넥션 유지\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 실시간으로 해당 뉴스 페이지에서 뉴스가 업로드되면 헤더와 업로드시간을 찍어주는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 정보가 성공적으로 저장되었습니다. 파일명: 2024-01-23_cryptocurrency_news_info.json\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Chrome 브라우저를 백그라운드에서 실행하도록 옵션 설정\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # 백그라운드 실행 옵션 추가\n",
    "\n",
    "# 크롬 드라이버 다운로드 및 실행 경로 지정 (자신의 크롬 드라이버 경로로 변경)\n",
    "chrome_driver_path = 'C:\\\\education\\\\ml_dev\\\\coin\\\\jh_-\\\\investing\\\\chromedriver-win64'\n",
    "\n",
    "# Selenium으로 웹페이지 열기 함수\n",
    "def get_news_info(url):\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # 페이지가 로딩되기를 기다림 (시간이 많이 걸릴 경우 조절 필요)\n",
    "    \n",
    "    # 현재 페이지 소스코드 가져오기\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 뉴스 제목과 올라온 시간 추출\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    news_info_list = []\n",
    "    \n",
    "    # 뉴스 제목과 올라온 시간이 포함된 요소 선택\n",
    "    news_elements = soup.select('.textDiv')\n",
    "    \n",
    "    for element in news_elements:\n",
    "        # 뉴스 제목 추출\n",
    "        title = element.select_one('.title').text.strip()\n",
    "        \n",
    "        # 올라온 시간 추출\n",
    "        time_element = element.select_one('.date')\n",
    "        if time_element:\n",
    "            time_info = time_element.text.strip()\n",
    "        else:\n",
    "            time_info = \"시간 정보 없음\"\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        news_info_list.append({'title': title, 'time': time_info})\n",
    "    \n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "    \n",
    "    return news_info_list\n",
    "\n",
    "# 뉴스 정보를 JSON 파일로 저장하는 함수\n",
    "def save_news_to_json(news_info_list):\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    file_name = f'{current_date}_cryptocurrency_news_info.json'\n",
    "    \n",
    "    result_data = {'news_info': news_info_list}\n",
    "    with open(file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(result_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"뉴스 정보가 성공적으로 저장되었습니다. 파일명: {file_name}\")\n",
    "\n",
    "# 주기적으로 웹페이지 새로고침하여 뉴스 데이터 가져오기\n",
    "while True:\n",
    "    url = \"https://www.investing.com/news/cryptocurrency-news/1\"  # 페이지 1만 확인\n",
    "    news_info = get_news_info(url)\n",
    "    save_news_to_json(news_info)\n",
    "    \n",
    "    # 5분마다 새로고침 (원하는 주기로 변경 가능)\n",
    "    time.sleep(300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
